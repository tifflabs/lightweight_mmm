{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##%pip install --upgrade pip\n",
    "\n",
    "%pip install lightweight_mmm==0.1.7\n",
    "%pip install immutabledict\n",
    "%pip install numpyro\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install statsmodels\n",
    "%pip install tensorflow==2.7.2\n",
    "%pip install jax jaxlib==0.4.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "import numpyro as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the relevant modules of the library\n",
    "from lightweight_mmm import lightweight_mmm\n",
    "from lightweight_mmm import optimize_media\n",
    "from lightweight_mmm import plot\n",
    "from lightweight_mmm import preprocessing\n",
    "from lightweight_mmm import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "#Read the data\n",
    "##%pip install openpyxl\n",
    "data = pd.read_excel('~/Downloads/mmm_data_clean_5.xlsx', sheet_name='mmm', header=0, index_col=0, keep_default_na=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group data and create variables\n",
    "agg_data = data.groupby([\"date\",\"channel\"])[[\"impressions\",\"spend\", \"conversions\",]].sum()\n",
    "\n",
    "\n",
    "#Create data variables and remove zeros\n",
    "media_data_raw = agg_data['impressions'].unstack().fillna(0)\n",
    "costs_raw = agg_data['spend'].unstack()\n",
    "sales_raw = agg_data['conversions'].groupby(\"date\").sum()\n",
    "\n",
    "print(media_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check data quality\n",
    "##%pip install seaborn\n",
    "import seaborn as sb\n",
    "corr =(data.corr())\n",
    "sb.heatmap(corr, cmap=\"Blues\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splitting data intoi train and test\n",
    "\n",
    "split_point = pd.Timestamp(\"2023-01-01\") # 28 days to end of data\n",
    "\n",
    "media_data_train = media_data_raw.loc[:split_point - pd.Timedelta(1,'D')]\n",
    "media_data_test = media_data_raw.loc[split_point:]\n",
    "\n",
    "target_train = sales_raw.loc[:split_point - pd.Timedelta(1,'D')]\n",
    "target_test = sales_raw.loc[split_point:]\n",
    "\n",
    "costs_train = costs_raw.loc[:split_point - pd.Timedelta(1,'D')].sum(axis=0).loc[media_data_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data\n",
    "print(media_data_train)\n",
    "print(costs_train)\n",
    "print(target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create simulated organic traffic as extra feature. \n",
    "#Using organic data as extra features can give you a more accurate view of paid media effects.\n",
    "\n",
    "import numpy as np\n",
    "organic_raw = pd.DataFrame({'organic_search': 0, 'organic_social': 0}, index=media_data_raw.index)\n",
    "organic_raw['organic_search'] = sales_raw.values/10 + np.random.randint(10000, 100000, organic_raw.shape[0])\n",
    "organic_raw['organic_social'] = sales_raw.values/10 + np.random.randint(10000, 100000, organic_raw.shape[0])\n",
    "print(organic_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Scaling data\n",
    "split_point = pd.Timestamp(\"2023-02-01\") # 28 days to end of data\n",
    "\n",
    "media_data_train = media_data_raw.loc[:split_point - pd.Timedelta(1,'D')]\n",
    "media_data_test = media_data_raw.loc[split_point:]\n",
    "\n",
    "organic_data_train = organic_raw.loc[:split_point - pd.Timedelta(1,'D')]\n",
    "organic_data_test = organic_raw.loc[split_point:]\n",
    "\n",
    "target_train = sales_raw.loc[:split_point - pd.Timedelta(1,'D')]\n",
    "target_test = sales_raw.loc[split_point:]\n",
    "\n",
    "costs_train = costs_raw.loc[:split_point - pd.Timedelta(1,'D')].sum(axis=0).loc[media_data_train.columns]\n",
    "\n",
    "media_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
    "organic_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
    "target_scaler = preprocessing.CustomScaler(\n",
    "    divide_operation=jnp.mean)\n",
    "cost_scaler = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
    "\n",
    "media_data_train_scaled = media_scaler.fit_transform(media_data_train.values)\n",
    "organic_data_train_scaled = organic_scaler.fit_transform(organic_data_train.values)\n",
    "target_train_scaled = target_scaler.fit_transform(target_train.values.squeeze())\n",
    "costs_scaled = cost_scaler.fit_transform(costs_train.values)\n",
    "\n",
    "media_data_test_scaled = media_scaler.transform(media_data_test.values)\n",
    "organic_data_test_scaled = organic_scaler.transform(organic_data_test.values)\n",
    "\n",
    "media_names = media_data_raw.columns\n",
    "TF_CPP_MIN_LOG_LEVEL=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Finding the right hyper-parameters\n",
    "\n",
    "adstock_models = [\"adstock\", \"hill_adstock\", \"carryover\"]\n",
    "degrees_season = [1,2,3]\n",
    "\n",
    "##Narrowing down hyper params\n",
    "adstock_models = [\"hill_adstock\"]\n",
    "degrees_season = [1]\n",
    "\n",
    "##A simple loop was added to do a tiny grid search to find the best value\n",
    "#for two parameters: the adstock transformation and degrees of seasonality. \n",
    "#We can ad all models but model will run significantly slower.\n",
    "\n",
    "for model_name in adstock_models: \n",
    "    for degrees in degrees_season:\n",
    "        mmm = lightweight_mmm.LightweightMMM(model_name=model_name)\n",
    "        mmm.fit(\n",
    "            media=media_data_train_scaled,\n",
    "            media_prior=costs_scaled,\n",
    "            target=target_train_scaled,\n",
    "            extra_features=organic_data_train_scaled,\n",
    "            number_warmup=1000,\n",
    "            number_samples=1000,\n",
    "            number_chains=1,\n",
    "            degrees_seasonality=degrees,\n",
    "            weekday_seasonality=True,\n",
    "            seasonality_frequency=365,\n",
    "            seed=1)\n",
    "    \n",
    "    prediction = mmm.predict(\n",
    "    media=media_data_test_scaled,\n",
    "    extra_features=organic_data_test_scaled,\n",
    "    target_scaler=target_scaler)\n",
    "    p = prediction.mean(axis=0)\n",
    "\n",
    "    mape = mean_absolute_percentage_error(target_test.values, p)\n",
    "    print(f\"model_name={model_name} degrees={degrees} MAPE={mape} samples={p[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model diagnostics Convergence Check\n",
    "mmm.print_summary()\n",
    "##Fitting check\n",
    "plot.plot_model_fit(media_mix_model=mmm, target_scaler=target_scaler)\n",
    "#Predictive check\n",
    "prediction = mmm.predict(\n",
    "    media=media_data_test,\n",
    "    #extra_features=organic_data_test[-1:, :],\n",
    "    target_scaler=target_scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retraining LightweightMMM --using all data not sampled\n",
    "costs = costs_raw.sum(axis=0).loc[media_names]\n",
    "\n",
    "media_scaler2 = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
    "organic_scaler2 = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
    "target_scaler2 = preprocessing.CustomScaler(\n",
    "    divide_operation=jnp.mean)\n",
    "cost_scaler2 = preprocessing.CustomScaler(divide_operation=jnp.mean)\n",
    "\n",
    "media_data_scaled = media_scaler2.fit_transform(media_data_raw.values)\n",
    "organic_data_scaled = organic_scaler2.fit_transform(organic_raw.values)\n",
    "target_scaled = target_scaler2.fit_transform(sales_raw.values)\n",
    "costs_scaled2 = cost_scaler2.fit_transform(costs.values)\n",
    "\n",
    "media_names = media_data_raw.columns\n",
    "\n",
    "mmm = lightweight_mmm.LightweightMMM(model_name=\"hill_adstock\")\n",
    "mmm.fit(media=media_data_scaled,\n",
    "        media_prior=costs_scaled2,\n",
    "        extra_features=organic_data_scaled,\n",
    "        target=target_scaled,\n",
    "        number_warmup=1000,\n",
    "        number_samples=1000,\n",
    "        number_chains=1,\n",
    "        degrees_seasonality=1,\n",
    "        weekday_seasonality=True,\n",
    "        seasonality_frequency=365,\n",
    "        seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter estimate check\n",
    "\n",
    "plot.plot_media_channel_posteriors(media_mix_model=mmm, channel_names=media_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Response curve check\n",
    "plot.plot_response_curves(media_mix_model=mmm, media_scaler=media_scaler, target_scaler=target_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check ROI\n",
    "plot.plot_bars_media_metrics(metric=roi_hat, channel_names=media_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Run budget optimizer\n",
    "prices = costs/media_data_raw.sum(axis=0)\n",
    "budget = 100 # your budget here\n",
    "solution = optimize_media.find_optimal_budgets(\n",
    "    n_time_periods=5,\n",
    "    media_mix_model=mmm,\n",
    "    extra_features=organic_data_scaled[-5:, :],\n",
    "    budget=budget,\n",
    "    prices=prices.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save the model\n",
    "utils.save_model(mmm, file_path='file_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load model\n",
    "utils.load_model(file_path: 'file_path')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
